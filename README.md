# Principles of Data Analytics

This repository contains my work for the Principles of Data Analytics module, part of the Science in Computing (Data Analytics) course at Atlantic Technological University (ATU). It includes weekly programming tasks.

## About This Repository 
 
Each week, we complete a task that applies key data analytics concepts, such as handling datasets, performing calculations, and visualizing data using Python. The tasks follow the outline provided by our lecturer, available [here](https://github.com/ianmcloughlin/principles_of_data_analytics/blob/main/assessment/tasks.md).  

## Tools & Libraries Used  

To complete these tasks, I use the following tools and libraries:  

- **Python**: The programming language used for all tasks. Download it [here](https://www.python.org/downloads/).  
- **Jupyter Notebook**: A web-based environment for running Python code. Learn more [here](https://jupyter.org/).  
- **Pandas**: A library for data manipulation and analysis. Documentation [here](https://pandas.pydata.org/docs/).  
- **NumPy**: A library for numerical computing. Documentation [here](https://numpy.org/doc/).  
- **Matplotlib**: A library for creating static, animated, and interactive visualizations in Python. Documentation [here](https://matplotlib.org/stable/contents.html).  
- **Scikit-learn**: A machine learning library that includes the Iris dataset used in some tasks. Documentation [here](https://scikit-learn.org/stable/).  
- **Seaborn**: A Python data visualization library based on matplotlib. Documentation [here](https://seaborn.pydata.org/).

## How to Run the Code  

To set up your environment and run the code in this repository, follow these steps:  

1. **Clone the repository**  
   ```bash
   git clone https://github.com/elainecazetta/principles_of_data_analytics.git
   cd principles_of_data_analytics
   ```  
2. **Install dependencies**  
   ```bash
   pip install pandas numpy matplotlib scikit-learn jupyter
   ```  
3. **Run Jupyter Notebook**  
   ```bash
   jupyter notebook
   ```  
4. **Open and run the weekly tasks**  
   - Navigate to the `.ipynb` files and run them in Jupyter Notebook.  

## Weekly Tasks  
- **Week 1**: Loaded the Iris dataset using sklearn and explained what load_iris() returns.   
- **Week 2**: Explored the dataset structure, including shape, feature names, and class labels.   
- **Week 3**: Calculated summary statistics like mean, median, min, max, and standard deviation.    
- **Week 4**: Created histograms to visualise the distribution of each feature.   
- **Week 5**: Plotted a scatter plot for two features with color-coded classes.  
- **Week 6**: Added a regression line to the scatter plot using NumPy.  
- **Week 7**: Made boxplots to compare petal lengths across classes.    
- **Week 8**: Calculated and visualised correlations between features with a heatmap.   
- **Week 9**: Computed R² for linear regression and added it to the scatter plot.  
- **Week 10**: Used seaborn’s pairplot to visualise all feature relationships and explained the plot.  

## References  
- GitHub’s [README best practices](https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/customizing-your-repository/about-readmes)  
- ATU's [course page](https://www.atu.ie/)  
